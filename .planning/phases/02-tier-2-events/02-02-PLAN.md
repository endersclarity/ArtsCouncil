---
phase: 02-tier-2-events
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - scripts/events/merge_events.py
  - scripts/events/family_keywords.json
  - .github/workflows/refresh-events.yml
autonomous: true

must_haves:
  truths:
    - "Running merge_events.py combines Trumba + LibCal + CivicEngage events into a single deduplicated list"
    - "Cross-source duplicates (same title + date) appear only once, with the Trumba version preferred"
    - "Family-friendly events are tagged with is_family: true using keyword classification"
    - "The GitHub Actions workflow runs daily and commits events-merged.json"
    - "events-merged.json includes generated_at timestamp and source_counts summary"
  artifacts:
    - path: "scripts/events/merge_events.py"
      provides: "Event merge, dedup, and family classification pipeline"
      min_lines: 120
    - path: "scripts/events/family_keywords.json"
      provides: "Configurable family keyword patterns"
      contains: "storytime"
    - path: ".github/workflows/refresh-events.yml"
      provides: "Daily cron workflow for event aggregation"
      contains: "cron"
  key_links:
    - from: "scripts/events/merge_events.py"
      to: "website/cultural-map-redesign/events-merged.json"
      via: "file output"
      pattern: "events-merged\\.json"
    - from: ".github/workflows/refresh-events.yml"
      to: "scripts/events/ingest_libcal_ical.py"
      via: "workflow step"
      pattern: "ingest_libcal_ical"
    - from: ".github/workflows/refresh-events.yml"
      to: "scripts/events/merge_events.py"
      via: "workflow step"
      pattern: "merge_events"
---

<objective>
Create the merge/dedup/classify pipeline that combines all three event sources into `events-merged.json`, and the GitHub Actions workflow that runs the full pipeline daily.

Purpose: This is the critical data pipeline that turns three separate event feeds into a single, deduplicated, classified dataset. Without it, the client has nothing new to display.
Output: A merge script, family keyword config, and a daily cron workflow.
</objective>

<execution_context>
@C:/Users/ender/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/ender/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-tier-2-events/02-RESEARCH.md
@.planning/phases/02-tier-2-events/02-01-SUMMARY.md
@scripts/events/ingest_trumba_rss.py
@scripts/events/build_event_index.py
@.github/workflows/refresh-hours.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Merge/dedup/classify script with family keywords config</name>
  <files>scripts/events/merge_events.py, scripts/events/family_keywords.json</files>
  <action>
Create `scripts/events/family_keywords.json`:
```json
{
  "positive_patterns": [
    "\\bstorytime\\b", "\\bstory\\s*time\\b",
    "\\bfor\\s+kids\\b", "\\bfor\\s+children\\b", "\\bfor\\s+families\\b",
    "\\bfamily[\\s-]friendly\\b", "\\ball\\s+ages\\b",
    "\\bages?\\s+\\d+[\\s-]+\\d+\\b",
    "\\bchildren'?s\\s+(program|event|craft|activity)\\b",
    "\\bkids?\\s+(program|event|craft|activity|club)\\b",
    "\\bteen\\b", "\\btween\\b", "\\bjunior\\b",
    "\\blego\\b", "\\bcraft\\s*time\\b", "\\bplay\\s*group\\b",
    "\\bstay\\s*&?\\s*play\\b"
  ],
  "negative_patterns": [
    "\\bchildren\\s+of\\b",
    "\\bfor\\s+adults\\s+only\\b",
    "\\b21\\+\\b", "\\b18\\+\\b",
    "\\bbar\\b.*\\bnight\\b"
  ]
}
```

Create `scripts/events/merge_events.py`:
- argparse CLI with:
  - `--trumba-file` (default: `website/cultural-map-redesign/events.json`)
  - `--libcal-file` (default: `website/cultural-map-redesign/events-libcal.json`)
  - `--civicengage-file` (default: `website/cultural-map-redesign/events-civicengage.json`)
  - `--output-file` (default: `website/cultural-map-redesign/events-merged.json`)
  - `--family-keywords` (default: `scripts/events/family_keywords.json`)
  - `--dedup-threshold` (default: 85, the rapidfuzz score threshold)

Pipeline steps:
1. **Load** all three source files. Each is `{"generated_at": "...", "events": [...]}`. If a file is missing or unparseable, log warning and skip (graceful degradation -- Trumba alone is valid).
2. **Normalize** all events to canonical schema. Trumba events from existing `events.json` may lack `source_label` -- add `"source_label": "Nevada County Arts Council"` and `"source_type": "feed"` if missing.
3. **Dedup** cross-source using `rapidfuzz.fuzz.token_sort_ratio`:
   - Group events by date (`start_iso[:10]`)
   - Within each date group, compare all pairs across different sources
   - Threshold: 85 (configurable via arg)
   - Title normalization: lowercase, strip leading "the/a/an", collapse whitespace
   - When duplicate found: keep Trumba > LibCal > CivicEngage (priority order). Merge `source_labels` list from all matched events onto the winner.
4. **Classify family** events using `family_keywords.json`:
   - Concatenate title + description + tags into search text
   - Check negative patterns first (any match -> `is_family: false`)
   - Check positive patterns (any match -> `is_family: true`)
   - Default: `is_family: false`
5. **Output** `events-merged.json`:
   ```json
   {
     "generated_at": "2026-02-14T08:00:00-08:00",
     "source_counts": {"trumba": 155, "libcal": 42, "civicengage": 3},
     "dedup_removed": 5,
     "family_tagged": 18,
     "events": [...]
   }
   ```
   Events sorted by `start_iso` then `event_id`.
6. **Run venue matching** by calling `build_event_index.py` on the merged output (or document that it should be run separately in the workflow).

Print summary to stderr: source counts, dedup removals, family tags, total output count.
  </action>
  <verify>
Run the full pipeline locally:
```bash
python scripts/events/ingest_trumba_rss.py
python scripts/events/ingest_libcal_ical.py
python scripts/events/ingest_civicengage_rss.py
python scripts/events/merge_events.py --output-file /tmp/events-merged.json
python -c "
import json
d = json.load(open('/tmp/events-merged.json'))
print(f'Total: {len(d[\"events\"])}, Sources: {d[\"source_counts\"]}, Deduped: {d[\"dedup_removed\"]}, Family: {d[\"family_tagged\"]}')
# Verify dedup worked: no two events with same date + very similar title
from collections import Counter
dates = Counter(e['start_iso'][:10] for e in d['events'])
print(f'Events across {len(dates)} dates')
# Verify family tags exist
family = [e for e in d['events'] if e.get('is_family')]
print(f'Family events: {len(family)}')
assert len(d['events']) > len(json.load(open('website/cultural-map-redesign/events.json'))), 'Merged should have MORE events than Trumba alone'
"
```
  </verify>
  <done>Merge script combines all sources, removes cross-source duplicates, classifies family events, and outputs events-merged.json with metadata. Total event count exceeds Trumba-only count.</done>
</task>

<task type="auto">
  <name>Task 2: GitHub Actions daily cron workflow</name>
  <files>.github/workflows/refresh-events.yml</files>
  <action>
Create `.github/workflows/refresh-events.yml` following the pattern of `refresh-hours.yml`:

```yaml
name: Refresh Events Data

on:
  schedule:
    - cron: "0 7 * * *"  # Daily at 7am UTC (midnight Pacific)
  workflow_dispatch:

permissions:
  contents: write

jobs:
  refresh-events:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scripts/requirements.txt

      - name: Ingest Trumba RSS
        run: python scripts/events/ingest_trumba_rss.py

      - name: Ingest LibCal iCal
        run: python scripts/events/ingest_libcal_ical.py

      - name: Ingest CivicEngage RSS
        run: python scripts/events/ingest_civicengage_rss.py
        continue-on-error: true  # CivicEngage is bonus, don't fail pipeline

      - name: Merge and deduplicate events
        run: python scripts/events/merge_events.py

      - name: Rebuild venue index
        run: python scripts/events/build_event_index.py

      - name: Validate merged events
        run: python scripts/events/validate_events.py

      - name: Commit updated event data
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): refresh events from Trumba + LibCal + CivicEngage"
          file_pattern: "website/cultural-map-redesign/events*.json"
          commit_user_name: "github-actions[bot]"
          commit_user_email: "github-actions[bot]@users.noreply.github.com"

      - name: Report completion
        if: always()
        run: |
          echo "Refresh Events workflow completed"
          python -c "import json; d=json.load(open('website/cultural-map-redesign/events-merged.json')); print(f'Total: {len(d[\"events\"])}, Sources: {d[\"source_counts\"]}')" || true
```

Key differences from refresh-hours.yml:
- Daily cron (not weekly) because events change more frequently than hours
- `continue-on-error: true` on CivicEngage step (bonus source)
- Commits all events*.json files (events.json, events-libcal.json, events-civicengage.json, events-merged.json, events.index.json)
- Runs validate_events.py to catch schema issues

Note: The `build_event_index.py` and `validate_events.py` steps assume these scripts can handle the merged JSON format. If they need adjustment, document what changes are needed but do NOT modify them in this plan (they're shared with the existing Trumba pipeline).
  </action>
  <verify>Validate the YAML syntax: `python -c "import yaml; yaml.safe_load(open('.github/workflows/refresh-events.yml'))"` (install PyYAML if needed, or just verify the file is valid YAML by inspection). Verify all script paths referenced in the workflow exist on disk.</verify>
  <done>GitHub Actions workflow file exists, references all four pipeline scripts in correct order, uses daily cron, and commits output files. CivicEngage step has continue-on-error for graceful degradation.</done>
</task>

</tasks>

<verification>
1. Full pipeline runs locally end-to-end: Trumba + LibCal + CivicEngage -> merge -> events-merged.json
2. events-merged.json has more events than events.json alone
3. No duplicate events (same date + very similar title) in merged output
4. Family events are tagged (at least some LibCal storytimes should be is_family: true)
5. GitHub Actions YAML is valid and references correct file paths
6. Missing source files don't crash the merge script (graceful fallback)
</verification>

<success_criteria>
The merge pipeline produces a deduplicated, family-classified events-merged.json that the client (Plan 03) can fetch. The GitHub Actions workflow automates daily refresh. If any single source fails, the pipeline still produces valid output from the remaining sources.
</success_criteria>

<output>
After completion, create `.planning/phases/02-tier-2-events/02-02-SUMMARY.md`
</output>
